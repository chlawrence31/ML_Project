{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0de2b4b8-c07c-4937-b2da-6921ef7e1d85",
      "metadata": {
        "id": "0de2b4b8-c07c-4937-b2da-6921ef7e1d85"
      },
      "source": [
        "# File Preprocessing  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2Qsfv6lnawro",
      "metadata": {
        "id": "2Qsfv6lnawro"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Run from google colab\n",
        "'''\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List files in the root of Google Drive\n",
        "drive_root = '/content/drive/My Drive/'\n",
        "for file_name in os.listdir(drive_root):\n",
        "    print(file_name)"
      ],
      "metadata": {
        "id": "gZHon4_cWw3Q"
      },
      "id": "gZHon4_cWw3Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Colab Extraction (ONLY USE ONCE)\n",
        "'''\n",
        "import zipfile\n",
        "\n",
        "# Path to your zip file in Google Drive\n",
        "zip_file_path = '/content/drive/My Drive/ML_FINAL_PROJECT.zip'\n",
        "extract_to_path = '/content/drive/My Drive/ML_FINAL_PROJECT/'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_to_path, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "\n",
        "print('Extraction complete.')\n",
        "'''"
      ],
      "metadata": {
        "id": "VOROSmtQa2OV"
      },
      "id": "VOROSmtQa2OV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dccfc712-8b89-4e03-a24a-8fd68c433495",
      "metadata": {
        "id": "dccfc712-8b89-4e03-a24a-8fd68c433495"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import shutil\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c48c2f32-9a75-4528-bb95-8c3f665578a8",
      "metadata": {
        "id": "c48c2f32-9a75-4528-bb95-8c3f665578a8"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import vgg16, VGG16_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1e52fdf-7274-4400-9c15-f06b0034d38b",
      "metadata": {
        "id": "b1e52fdf-7274-4400-9c15-f06b0034d38b"
      },
      "outputs": [],
      "source": [
        "cwd_path = Path.cwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b59e1e15-82cf-4d10-bff9-0c84bcfa118b",
      "metadata": {
        "id": "b59e1e15-82cf-4d10-bff9-0c84bcfa118b"
      },
      "outputs": [],
      "source": [
        "og_train_path = os.path.join(cwd_path, \"drive/MyDrive/ML_FINAL_PROJECT/ML_FINAL_PROJECT/fruits-360/Training\")\n",
        "og_test_path  = os.path.join(cwd_path, \"drive/MyDrive/ML_FINAL_PROJECT/ML_FINAL_PROJECT/fruits-360/Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ae548c-1fa3-4c88-a023-352821e556e4",
      "metadata": {
        "id": "81ae548c-1fa3-4c88-a023-352821e556e4"
      },
      "outputs": [],
      "source": [
        "def getRandomFruitDirs(classCount):\n",
        "    return np.random.choice(os.listdir(og_train_path), classCount, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca32de72-656a-4af2-ae40-45aa3193e401",
      "metadata": {
        "id": "ca32de72-656a-4af2-ae40-45aa3193e401"
      },
      "outputs": [],
      "source": [
        "def MakeDirs(srcDir, newDirs):\n",
        "\n",
        "    if type(newDirs) == str:\n",
        "        dirpath = os.path.join(srcDir, newDirs)\n",
        "        if os.path.isdir(dirpath):\n",
        "            shutil.rmtree(dirpath)\n",
        "\n",
        "        os.mkdir(dirpath)\n",
        "\n",
        "\n",
        "    if type(newDirs) == list:\n",
        "        for dirname in newDirs:\n",
        "            dirpath = os.path.join(srcDir, dirname)\n",
        "            if os.path.isdir(dirpath):\n",
        "                shutil.rmtree(dirpath)\n",
        "\n",
        "            os.mkdir(dirpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d6d858e-0136-4377-bbf6-0b7d6b974a6c",
      "metadata": {
        "id": "0d6d858e-0136-4377-bbf6-0b7d6b974a6c"
      },
      "outputs": [],
      "source": [
        "def transferFile(srcPaths, destDir):\n",
        "    if not os.path.isdir(destDir):\n",
        "        os.mkdir(destDir)\n",
        "\n",
        "    for idx, imagePth in enumerate(srcPaths):\n",
        "        dPath = os.path.join(destDir, f\"img{idx}.jpg\")\n",
        "        os.symlink(imagePth, dPath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3424bfbe-9bd9-4433-8a6f-0ddabdf5a9a4",
      "metadata": {
        "id": "3424bfbe-9bd9-4433-8a6f-0ddabdf5a9a4"
      },
      "outputs": [],
      "source": [
        "def getImageMatrix(links, title, image_size):\n",
        "\n",
        "    sub_matrix = np.zeros(image_size[0] * image_size[1] * 3)\n",
        "    labels = []\n",
        "    for link in links:\n",
        "        vect_item = cv2.imread(link)\n",
        "        vect_item = cv2.resize(vect_item, image_size)\n",
        "        vect_item = cv2.cvtColor(vect_item, cv2.COLOR_BGR2RGB)\n",
        "        sub_matrix = np.vstack((sub_matrix, vect_item.flatten()))\n",
        "        labels.append(title)\n",
        "\n",
        "    return sub_matrix[1:]/255, np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db290e82-2a3f-4a77-aa73-76c219a9b8de",
      "metadata": {
        "id": "db290e82-2a3f-4a77-aa73-76c219a9b8de"
      },
      "outputs": [],
      "source": [
        "def getSamplesDir(sampleSize, valSize, testSize, selectedFruits, classDist = None):\n",
        "    trainSize = 1 - (valSize + testSize)\n",
        "    train_fn = []\n",
        "    test_fn = []\n",
        "    val_fn = []\n",
        "\n",
        "    if classDist is None:\n",
        "        cDist = np.ones(selectedFruits.shape[0]) * 1/selectedFruits.shape[0]\n",
        "    else:\n",
        "        cDist = classDist\n",
        "\n",
        "    if np.abs(np.sum(cDist) - 1) > 1e-9:\n",
        "        raise Exception(\"Class Distribution is greater than one!\")\n",
        "\n",
        "\n",
        "    if testSize <= 0:\n",
        "        raise Exception(\"Training sample size too small!\")\n",
        "\n",
        "    train_sample_sz = int(trainSize * sampleSize)\n",
        "    val_sample_sz = int(valSize * sampleSize)\n",
        "    test_sample_sz = int(testSize * sampleSize)\n",
        "\n",
        "    subset_dir = \"ML_FINAL_PROJECT/fruits-360\"\n",
        "    MakeDirs(subset_dir, \"Subsets\")\n",
        "\n",
        "    subset_dir = \"ML_FINAL_PROJECT/fruits-360/Subsets\"\n",
        "\n",
        "    subs = [\"Train_sub\", \"Validation_sub\", \"Test_sub\"]\n",
        "    MakeDirs(\"ML_FINAL_PROJECT/fruits-360/Subsets\", subs)\n",
        "\n",
        "    for idx, fruit in enumerate(selectedFruits):\n",
        "        globbed_train = glob(os.path.join(og_train_path, fruit, \"*.jp*g\"))\n",
        "        globbed_test = glob(os.path.join(og_test_path, fruit, \"*.jp*g\"))\n",
        "\n",
        "        train_fn = np.random.choice(globbed_train, int(train_sample_sz * cDist[idx]), replace = False)\n",
        "        testval_fn = np.random.choice(globbed_test, int((test_sample_sz  + val_sample_sz)*cDist[idx]), replace = False)\n",
        "\n",
        "        test_fn, val_fn = testval_fn[ : int(test_sample_sz * cDist[idx])],  testval_fn[int(test_sample_sz * cDist[idx]) + 1 :]\n",
        "\n",
        "        transferFile(train_fn, os.path.join(subset_dir, subs[0], fruit))\n",
        "        transferFile(val_fn, os.path.join(subset_dir, subs[1], fruit))\n",
        "        transferFile(test_fn, os.path.join(subset_dir, subs[2], fruit))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "647840d4-9cac-4958-a52b-95fdac7b8c23",
      "metadata": {
        "id": "647840d4-9cac-4958-a52b-95fdac7b8c23"
      },
      "outputs": [],
      "source": [
        "def getSamplesMat(sampleSize, selectedFruits, classDist = None, resize = (100, 100)):\n",
        "    matrix = np.zeros(shape = (1, resize[0] * resize[1] * 3))\n",
        "    labels = np.zeros(0)\n",
        "\n",
        "    if classDist is None:\n",
        "        cDist = np.ones(selectedFruits.shape[0]) * 1/selectedFruits.shape[0]\n",
        "    else:\n",
        "        cDist = classDist\n",
        "\n",
        "    if np.abs(np.sum(cDist) - 1) > 1e-9:\n",
        "        raise Exception(\"Class Distribution is greater than one!\")\n",
        "        return\n",
        "\n",
        "\n",
        "    for idx, fruit in enumerate(selectedFruits):\n",
        "        globbed_train = glob(os.path.join(og_train_path, fruit, \"*.jp*g\"))\n",
        "        globbed_test = glob(os.path.join(og_test_path, fruit, \"*.jp*g\"))\n",
        "\n",
        "        fn = np.random.choice(globbed_train + globbed_test, int(sampleSize * cDist[idx]) ,replace = False)\n",
        "        res_matrix, new_labels = getImageMatrix(fn, fruit,resize)\n",
        "\n",
        "        matrix = np.vstack([matrix, res_matrix])\n",
        "        labels = np.concatenate([labels, new_labels])\n",
        "\n",
        "    return matrix[1:], labels, fn[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def GrayScaleImageSquare(dataset, flatten=True):\n",
        "\n",
        "    if len(dataset.shape) == 2:\n",
        "        try:\n",
        "            dim = int(np.floor(np.sqrt(dataset.shape[1]/3)))\n",
        "        except:\n",
        "            raise Exception(\"Singular images may not work, use reshape(-1)\")\n",
        "\n",
        "\n",
        "        try:\n",
        "            dataset = dataset.reshape(-1, dim, dim, 3)\n",
        "        except:\n",
        "            raise Exception(\"Input image is probably not colored\")\n",
        "    elif len(dataset.shape) == 4:\n",
        "        dim = dataset.shape[1]\n",
        "\n",
        "    grayConv = np.zeros(shape = [dataset.shape[0], dim, dim]);\n",
        "    for idx, image in enumerate(dataset):\n",
        "        gray_image = cv2.cvtColor(image.astype('float32'), cv2.COLOR_BGR2GRAY)\n",
        "        grayConv[idx] = gray_image\n",
        "\n",
        "    if flatten == True:\n",
        "        grayConv = grayConv.reshape(-1, dim**2)\n",
        "\n",
        "    return grayConv"
      ],
      "metadata": {
        "id": "RwsTO7LUtnnp"
      },
      "id": "RwsTO7LUtnnp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ca2d779d-6bad-4202-adfd-9de9a35fd3b7",
      "metadata": {
        "id": "ca2d779d-6bad-4202-adfd-9de9a35fd3b7"
      },
      "source": [
        "# Pulling the images using the matrix command (For all but Neural Networks):"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tS20pAUst239"
      },
      "id": "tS20pAUst239",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1e98ac6-a5ae-473b-9370-7827979c9658",
      "metadata": {
        "id": "c1e98ac6-a5ae-473b-9370-7827979c9658"
      },
      "outputs": [],
      "source": [
        "# Specify fruit classes here or get n random fruits\n",
        "count = 40\n",
        "classes = getRandomFruitDirs(count) #or [\"Madarine\", \"Apple Golden 1\" ... etc ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = classes[classes != '.ipynb_checkpoints']"
      ],
      "metadata": {
        "id": "TEMbgbrHoL0N"
      },
      "id": "TEMbgbrHoL0N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6f0383d-95a7-4223-a0e6-bd040996d2d4",
      "metadata": {
        "id": "d6f0383d-95a7-4223-a0e6-bd040996d2d4"
      },
      "outputs": [],
      "source": [
        "# overall Sample size:\n",
        "sample_size = 1000\n",
        "\n",
        "# Selected fruit classes (from above)\n",
        "selected_fruits = classes\n",
        "\n",
        "# Would contain the fraction distribution of classes for experimentation (None is all equal)\n",
        "classDist = None # ex: [0.2, 0.1, 0.4, 0.1, 0.1] MUST ADD TO 1\n",
        "\n",
        "# resize: Resizes the image for further experimentation default is 100 x 100\n",
        "resizes = (100, 100)\n",
        "\n",
        "\n",
        "image_dataset, labels, what = getSamplesMat(sample_size, selected_fruits, classDist, resizes)\n",
        "image_dataset = GrayScaleImageSquare(image_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b7f3cef-d1e1-4ed6-a164-cebd41e5274c",
      "metadata": {
        "id": "0b7f3cef-d1e1-4ed6-a164-cebd41e5274c"
      },
      "outputs": [],
      "source": [
        "print(\"Dataset shape \\\"sample_size\\\" images of shape 3*resizes[1]*resizes[2] is: \", image_dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a360c28-b191-4df4-9cdb-a8fc863d44b4",
      "metadata": {
        "id": "9a360c28-b191-4df4-9cdb-a8fc863d44b4"
      },
      "outputs": [],
      "source": [
        "image_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18296566-941c-4d94-9a4d-f61e0ea07809",
      "metadata": {
        "id": "18296566-941c-4d94-9a4d-f61e0ea07809"
      },
      "outputs": [],
      "source": [
        "labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd87fd5b-e0ae-4064-83e5-6682aff39c6f",
      "metadata": {
        "id": "dd87fd5b-e0ae-4064-83e5-6682aff39c6f"
      },
      "outputs": [],
      "source": [
        "# display an image:\n",
        "\n",
        "# Reshape the image to the resizes coordinates:\n",
        "\n",
        "# image index (change)\n",
        "index = 10\n",
        "image = image_dataset[index].reshape(resizes[0], resizes[1], 3)\n",
        "plt.imshow(image)\n",
        "plt.title(labels[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da0900a0-1cfe-4448-94a9-9700df9308fc",
      "metadata": {
        "id": "da0900a0-1cfe-4448-94a9-9700df9308fc"
      },
      "source": [
        "# Using a CNN with 20 fruit classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10484cb7-8bbd-4647-b262-3cebdc4789f6",
      "metadata": {
        "id": "10484cb7-8bbd-4647-b262-3cebdc4789f6"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchsummary as summary\n",
        "\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colored Fruitss\n",
        "red_fruits = [\n",
        "    \"Grape Pink\", \"Tomato Cherry Red\", \"Tomato Maroon\", \"Apple Pink Lady\", \"Apricot\",\n",
        "    \"Tomato 1\", \"Peach\", \"Cherry 2\", \"Apple Braeburn\", \"Tomato Heart\",\n",
        "    \"Pepper Red\", \"Pomegranate\", \"Mango Red\", \"Pear Red\", \"Kaki\", \"Onion Red\",\n",
        "    \"Strawberry\", \"Tamarillo\", \"Cucumber Ripe\", \"Pear Forelle\"\n",
        "]\n",
        "\n",
        "\n",
        "yellow_orange_fruits = [\n",
        "    \"Pepper Yellow\", \"Grapefruit Pink\", \"Tomato Yellow\", \"Mandarine\", \"Tangelo\",\n",
        "    \"Grapefruit White\", \"Cherry Wax Yellow\", \"Kaki\", \"Peach 2\", \"Apple Red Yellow 1\",\n",
        "    \"Lemon\", \"Pomelo Sweetie\", \"Pear Red\", \"Pepper Orange\", \"Peach\", \"Maracuja\",\n",
        "    \"Apricot\", \"Cucumber Ripe 2\", \"Carambula\", \"Tomato 2\"\n",
        "]\n",
        "\n",
        "green_fruits = ['Pepper Green', 'Grape White 4', 'Grape Blue',\n",
        "         'Tomato not Ripened', 'Avocado', 'Grape White 3',\n",
        "         'Cherry Wax Black', 'Blueberry', 'Cherry 1', 'Plum 3', 'Plum',\n",
        "         'Nut Forest', 'Mango', 'Pomelo Sweetie', 'Limes', 'Pineapple',\n",
        "         'Apple Granny Smith', 'Guava', 'Watermelon', 'Apple Golden 3']\n",
        "\n",
        "# Fruit Shapes\n",
        "\n",
        "\n",
        "circular_fruits = [\n",
        "    \"Cantaloupe 1\", \"Cantaloupe 2\", \"Cherry 1\", \"Cherry 2\", \"Apricot\",\n",
        "    \"Cherry Wax Black\", \"Cherry Wax Red\", \"Cherry Wax Yellow\", \"Clementine\",\n",
        "    \"Grape Blue\", \"Grape White\", \"Grapefruit Pink\", \"Nectarine\", \"Orange\",\n",
        "    \"Peach\", \"Plum\", \"Plum 2\", \"Tomato Cherry Red\", \"Walnut\", \"Watermelon\"\n",
        "]\n",
        "\n",
        "no_circular_fruits = [\n",
        "    \"Apple Braeburn\", \"Apple Crimson Snow\", \"Apple Golden 1\", \"Apple Granny Smith\",\n",
        "    \"Apple Pink Lady\", \"Apple Red 1\", \"Apple Red Delicious\", \"Apple Red Yellow 1\",\n",
        "    \"Beetroot\", \"Blueberry\", \"Fig\", \"Guava\", \"Lemon\", \"Limes\", \"Onion Red\",\n",
        "    \"Onion White\", \"Pepper Red\", \"Lemon Meyer\", \"Mango Red\", \"Kiwi\"\n",
        "]\n",
        "\n",
        "tubular_fruits = [\n",
        "    \"Eggplant\", \"Avocado\", \"Avocado Ripe\", \"Banana\", \"Banana Lady Finger\", \"Banana Red\",\n",
        "    \"Cactus fruit\", \"Carambula\", \"Corn\", \"Cucumber Ripe\", \"Hazelnut\", \"Kumquats\",\n",
        "    \"Pear 2\", \"Pear Red\", \"Pepino\", \"Tomato 2\", \"Nut Pecan\", \"Melon Piel de Sapo\",\n",
        "    \"Pear Abate\", \"Corn Husk\"\n",
        "]\n",
        "\n",
        "random40 = getRandomFruitDirs(40)\n",
        "\n",
        "ds_name = \"Green Fruits (Greyscaled)\""
      ],
      "metadata": {
        "id": "kets9gxMtHAK"
      },
      "id": "kets9gxMtHAK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# overall Sample size:\n",
        "sample_size = 1000\n",
        "\n",
        "\n",
        "# Selected fruit classes (from above)\n",
        "selected_fruits = np.array(green_fruits)\n",
        "\n",
        "# Would contain the fraction distribution of classes for experimentation (None is all equal)\n",
        "classDist = None # ex: [0.2, 0.1, 0.4, 0.1, 0.1] MUST ADD TO 1\n",
        "\n",
        "# resize: Resizes the image for further experimentation default is 100 x 100\n",
        "resizes = (100, 100)\n",
        "\n",
        "\n",
        "image_dataset, labels, what = getSamplesMat(sample_size, selected_fruits, classDist, resizes)\n",
        "image_dataset = GrayScaleImageSquare(image_dataset)"
      ],
      "metadata": {
        "id": "1hRz9ynNtI3L"
      },
      "id": "1hRz9ynNtI3L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fdb9e51-23f7-41fb-a2ee-420c1b0e5bd5",
      "metadata": {
        "id": "6fdb9e51-23f7-41fb-a2ee-420c1b0e5bd5"
      },
      "outputs": [],
      "source": [
        "ImageDataReshaped = image_dataset.reshape(-1, resizes[0], resizes[1],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "458636f4-9bc6-4415-bcd4-1fdf8133e3d7",
      "metadata": {
        "id": "458636f4-9bc6-4415-bcd4-1fdf8133e3d7"
      },
      "outputs": [],
      "source": [
        "class CustomDataset:\n",
        "    def __init__(self, tensors, transforms):\n",
        "        #assert all(tensors[0].size(0) == tensors.size(0) for tensor in tensors), \"size mismatch\"\n",
        "        self.tensors = tensors\n",
        "        self.trans = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.trans != None:\n",
        "            x = self.trans(self.tensors[0][index])\n",
        "            y = self.tensors[1][index]\n",
        "        else:\n",
        "            x = self.tensors[0][index]\n",
        "            y = self.tensors[1][index]\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.tensors[0].size(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61f2ae6f-65ad-46ef-be59-c76effb9f04b",
      "metadata": {
        "id": "61f2ae6f-65ad-46ef-be59-c76effb9f04b"
      },
      "outputs": [],
      "source": [
        "crop_factor = 1\n",
        "cropSz = int(resizes[0] * crop_factor)\n",
        "transforms_Basic = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.RandomCrop(cropSz),\n",
        "    T.RandomRotation(20),\n",
        "    T.ToTensor()\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c07c6d20-b2ed-4d0e-8b88-2b0acf090bf0",
      "metadata": {
        "id": "c07c6d20-b2ed-4d0e-8b88-2b0acf090bf0"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "addbfc98-5b9e-46ae-bb63-09a9f4be2b15",
      "metadata": {
        "id": "addbfc98-5b9e-46ae-bb63-09a9f4be2b15"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(ImageDataReshaped,labels, test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fefec60-17e6-45eb-8da7-b4d1cb399d90",
      "metadata": {
        "id": "8fefec60-17e6-45eb-8da7-b4d1cb399d90"
      },
      "outputs": [],
      "source": [
        "unq_train = np.unique(y_train)\n",
        "unq_test = np.unique(y_test)\n",
        "\n",
        "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 5))\n",
        "\n",
        "sns.countplot(x=y_train, ax = ax[0])\n",
        "ax[0].set_title(\"Train Dist\")\n",
        "ax[0].set_xticks(np.arange(unq_train.shape[0]), unq_train, rotation=45, ha='right')\n",
        "\n",
        "sns.countplot(x=y_test, ax = ax[1])\n",
        "ax[1].set_title(\"Test Dist\")\n",
        "ax[1].set_xticks(np.arange(unq_test.shape[0]), unq_test, rotation=45, ha='right')\n",
        "\n",
        "fig.suptitle(\"Class Distribution\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad0a275-9721-4c99-a151-0154dd1b2328",
      "metadata": {
        "id": "3ad0a275-9721-4c99-a151-0154dd1b2328"
      },
      "outputs": [],
      "source": [
        "y_train = torch.tensor(le.fit_transform(y_train)).long()\n",
        "y_test = torch.tensor(le.transform(y_test)).long()\n",
        "X_train = torch.tensor(X_train).float()\n",
        "X_test = torch.tensor(X_test).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bee94cb-e83a-423a-9ed9-de4fda2a903a",
      "metadata": {
        "id": "4bee94cb-e83a-423a-9ed9-de4fda2a903a"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.permute(0,3,1,2)\n",
        "X_test = X_test.permute(0,3,1,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7jcIn_LSeYf2",
      "metadata": {
        "id": "7jcIn_LSeYf2"
      },
      "outputs": [],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80500918-e317-4bec-807c-570bb924b33c",
      "metadata": {
        "id": "80500918-e317-4bec-807c-570bb924b33c"
      },
      "outputs": [],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "R0WUBJoseaE4",
      "metadata": {
        "id": "R0WUBJoseaE4"
      },
      "source": [
        "# Testing a Basic CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4104f1f9-73f8-43ac-888d-5cb08cc81632",
      "metadata": {
        "id": "4104f1f9-73f8-43ac-888d-5cb08cc81632"
      },
      "outputs": [],
      "source": [
        "# Creating a simple CNN model to train the network:\n",
        "def CreateCNNModel(n_outputs, n_imgSize):\n",
        "    class CnnModel(nn.Module):\n",
        "        def __init__(self, n_outputs, n_imgSize):\n",
        "            super().__init__()\n",
        "\n",
        "            # Setting universal parameters\n",
        "            self.kernel = 3\n",
        "            self.pad = 0\n",
        "            self.stride = 1\n",
        "            self.pool = 2\n",
        "            self.gradient = None\n",
        "\n",
        "            # Assumes the image remains square\n",
        "            self.imgSize = n_imgSize\n",
        "\n",
        "            self.conv1 = nn.Conv2d(1, 8, self.kernel, self.stride, self.pad)\n",
        "\n",
        "            outSize = int(np.floor((self.imgSize[0] + 2*self.pad - self.kernel)//self.stride) + 1)\n",
        "            outSize = outSize//self.pool\n",
        "\n",
        "            self.conv2 = nn.Conv2d(8, 16, self.kernel, self.stride, self.pad)\n",
        "\n",
        "            outSize = int(np.floor((outSize + 2*self.pad - self.kernel)//self.stride) + 1)\n",
        "            outSize = outSize//self.pool\n",
        "\n",
        "            self.conv3 = nn.Conv2d(16, 32, self.kernel, self.stride, self.pad)\n",
        "\n",
        "            outSize = int(np.floor((outSize + 2*self.pad - self.kernel)//self.stride) + 1)\n",
        "            outSize = outSize//self.pool\n",
        "\n",
        "            self.bnorm1 = nn.BatchNorm2d(32)\n",
        "\n",
        "            self.flatten = nn.Flatten()\n",
        "\n",
        "            self.fc1 = nn.Linear(outSize**2 * 32, 50)\n",
        "            self.fc2 = nn.Linear(50, n_outputs)\n",
        "\n",
        "        def activations_hook(self, grad):\n",
        "            self.gradient = grad\n",
        "\n",
        "        def get_activations_hook(self):\n",
        "            return self.gradient\n",
        "\n",
        "        def getFeatures(self, x):\n",
        "            x = F.relu(self.conv1(x))\n",
        "            x = F.max_pool2d(x, self.pool, self.pool)\n",
        "\n",
        "            x = F.relu(self.conv2(x))\n",
        "            x = F.max_pool2d(x, self.pool, self.pool)\n",
        "\n",
        "            x = F.relu(self.conv3(x))\n",
        "            x = F.max_pool2d(x, self.pool, self.pool)\n",
        "            return x\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = F.relu(self.conv1(x))\n",
        "            x = F.max_pool2d(x, self.pool, self.pool)\n",
        "\n",
        "            x = F.relu(self.conv2(x))\n",
        "            x = F.max_pool2d(x, self.pool, self.pool)\n",
        "\n",
        "            x = F.relu(self.conv3(x))\n",
        "            # Enable hook if doing grad cam\n",
        "            #h = x.register_hook(self.activations_hook)\n",
        "            x = F.max_pool2d(x, self.pool, self.pool)\n",
        "\n",
        "            x = self.bnorm1(x)\n",
        "            x = self.flatten(x)\n",
        "\n",
        "            x = F.relu(self.fc1(x))\n",
        "            x = self.fc2(x)\n",
        "            return x\n",
        "\n",
        "\n",
        "    model = CnnModel(n_outputs, n_imgSize)\n",
        "    lossfunc = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    return model, lossfunc, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69ae13a7-dc1f-48eb-803d-f51dcb0b96b4",
      "metadata": {
        "id": "69ae13a7-dc1f-48eb-803d-f51dcb0b96b4"
      },
      "outputs": [],
      "source": [
        "train = CustomDataset((X_train, y_train), transforms_Basic)\n",
        "test = CustomDataset((X_train, y_train), None)\n",
        "\n",
        "train_loader = DataLoader(train, batch_size = 32, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size = test.tensors[0].shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructing and testing the model:"
      ],
      "metadata": {
        "id": "O1_f78yAy0m5"
      },
      "id": "O1_f78yAy0m5"
    },
    {
      "cell_type": "code",
      "source": [
        "class_sz = len(np.unique(y_train))"
      ],
      "metadata": {
        "id": "7C7RcNv-yx0i"
      },
      "id": "7C7RcNv-yx0i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, lossfunc, optimizer = CreateCNNModel(class_sz, resizes)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "UPOoMBwlyrj_"
      },
      "id": "UPOoMBwlyrj_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_base,y_base = next(iter(train_loader))\n",
        "x_base = x_base.to(device)\n",
        "test_results = model(x_base)"
      ],
      "metadata": {
        "id": "oURNwUfbyBgV"
      },
      "id": "oURNwUfbyBgV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 4\n",
        "plt.imshow(x_base[idx].cpu().permute(1,2,0).detach().numpy())\n",
        "plt.title(y_base[idx].item())"
      ],
      "metadata": {
        "id": "SxvmKLTyxTZz"
      },
      "id": "SxvmKLTyxTZz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6f31f67e-ff98-4059-a4c2-b8f841f9d046",
      "metadata": {
        "id": "6f31f67e-ff98-4059-a4c2-b8f841f9d046"
      },
      "source": [
        "# Model Training Function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d4291c-3962-471e-9ab5-0d0032bfe19a",
      "metadata": {
        "id": "92d4291c-3962-471e-9ab5-0d0032bfe19a"
      },
      "outputs": [],
      "source": [
        "#\n",
        "def TrainModel(net, lossfunc, optimizer, train_loader, test_loader, epochs = 50, val_set = True):\n",
        "    train_acc_hist = []\n",
        "    train_loss_hist = []\n",
        "    test_acc_hist = []\n",
        "    test_loss_hist = []\n",
        "    net.train()\n",
        "\n",
        "    for epochi in range(epochs):\n",
        "        batch_acc = []\n",
        "        batch_loss = []\n",
        "        for x, y in train_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            pred = net(x)\n",
        "            loss = lossfunc(pred, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            batch_loss.append(loss.cpu().item())\n",
        "            acc_score = 100 * torch.mean((torch.argmax(pred.cpu(), dim=1) == y.cpu()).float())\n",
        "            batch_acc.append(acc_score.detach().numpy())\n",
        "\n",
        "        train_acc_hist.append(np.mean(batch_acc))\n",
        "        train_loss_hist.append(np.mean(batch_loss))\n",
        "\n",
        "        if val_set:\n",
        "          X_test, y_test = next(iter(test_loader))\n",
        "          X_test = X_test.to(device)\n",
        "          y_test = y_test.to(device)\n",
        "          net.eval()\n",
        "          with torch.no_grad():\n",
        "              y_hat = net(X_test)\n",
        "              test_loss = lossfunc(y_hat, y_test)\n",
        "              test_loss_hist.append(test_loss.item())\n",
        "              test_acc = 100*torch.mean((torch.argmax(y_hat.cpu(), dim=1) == y_test.cpu()).float())\n",
        "              test_acc_hist.append(test_acc.detach().numpy())\n",
        "\n",
        "    return train_loss_hist, test_loss_hist, train_acc_hist, test_acc_hist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "964b30a6-d5e1-4b56-98a7-94b3877e63da",
      "metadata": {
        "id": "964b30a6-d5e1-4b56-98a7-94b3877e63da"
      },
      "outputs": [],
      "source": [
        "train_loss, test_loss, train_acc, test_acc = TrainModel(model, lossfunc, optimizer, train_loader, test_loader, val_set=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics:\n",
        "fig, ax = plt.subplots(nrows = 1, ncols=2, figsize=(10, 5))\n",
        "fig.suptitle(f\"CNN Metrics for {ds_name}\")\n",
        "ax[0].plot(train_loss, label=\"Train Loss\")\n",
        "ax[0].plot(test_loss, label=\"Test Loss\")\n",
        "ax[0].set_title(\"Model Loss\")\n",
        "ax[0].set_ylabel(\"Loss (CCE)\")\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "\n",
        "ax[1].plot(train_acc, label=\"Train\")\n",
        "ax[1].plot(test_acc, label=\"Test\")\n",
        "ax[1].set_title(\"Model Accuracy\")\n",
        "ax[1].set_ylabel(\"Accuracy (%)\")\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "n6QvT9jHuwBg"
      },
      "id": "n6QvT9jHuwBg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = next(iter(test_loader))\n",
        "x_test = x_test.to(device)\n",
        "y_hat = model(x_test)\n",
        "preds = torch.argmax(y_hat.cpu(), dim=1)\n",
        "\n",
        "print(f\"Classification Report for {ds_name}:\")\n",
        "print(classification_report(preds, y_test))"
      ],
      "metadata": {
        "id": "ZiOARy53uwe7"
      },
      "id": "ZiOARy53uwe7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(preds, y_test)\n",
        "sns.heatmap(conf_matrix, annot = True)\n",
        "plt.title(f\"Confusion Matrix for CNN with {ds_name}\")\n",
        "\n",
        "plt.xticks(np.arange(len(selected_fruits)) + 0.5, selected_fruits, rotation=90);\n",
        "plt.yticks(np.arange(len(selected_fruits)) + 0.5, selected_fruits, rotation = 360);\n",
        "\n"
      ],
      "metadata": {
        "id": "oCt8rVqquz2T"
      },
      "id": "oCt8rVqquz2T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Source: https://medium.com/@stepanulyanin/implementing-grad-cam-in-pytorch-ea0937c31e82\n",
        "def GrabGradCam(image, correct_label, vgg_model):\n",
        "    vgg_model.eval()\n",
        "    prediction = vgg_model(image)\n",
        "    prediction[0][correct_label].backward()\n",
        "    final_activations = vgg_model.get_activations_hook()\n",
        "    # global average pool the final activations (512 and 12 of them)\n",
        "    fa_mean = final_activations.mean(dim=[0,2,3])\n",
        "    # inititalize the activations:\n",
        "    weighted_activations = vgg_model.getFeatures(image).detach()[0]\n",
        "    for idx in range(len(weighted_activations)):\n",
        "        weighted_activations[idx] *= fa_mean[idx]\n",
        "    # unsqueeze the weighted acitvations\n",
        "    weighted_activations = weighted_activations.unsqueeze(0)\n",
        "    # weighted_heatmap:\n",
        "    weighted_activations = weighted_activations.mean(dim = 1).squeeze()\n",
        "\n",
        "    # Normalizing the heatmap\n",
        "    heatmap = torch.maximum(weighted_activations, torch.tensor(0))\n",
        "    heatmap /= torch.max(heatmap)\n",
        "    heatmap = heatmap.cpu().detach().numpy()\n",
        "\n",
        "    heatmap = cv2.resize(heatmap, (image.shape[2], image.shape[3]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    og_img = image[0].cpu().detach().permute(1,2,0).numpy() * 255\n",
        "    og_img = og_img.astype(np.uint8)\n",
        "    superimposed_img = heatmap * 0.4 + og_img\n",
        "    return superimposed_img/np.max(superimposed_img)"
      ],
      "metadata": {
        "id": "pv0Fx_uE9Y0V"
      },
      "id": "pv0Fx_uE9Y0V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the GrabGradCam model:\n",
        "test, label = next(iter(test_loader))\n",
        "test_img = test[10].unsqueeze(0).to(device)\n",
        "test_label = label[10].to(device)"
      ],
      "metadata": {
        "id": "sbluNxED-xQ1"
      },
      "id": "sbluNxED-xQ1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "plt.imshow(GrabGradCam(test_img, test_label, model))\n",
        "pred = model(test_img).cpu()\n",
        "pred_class = torch.argmax(pred, dim = 1)\n",
        "pred_name = le.inverse_transform(pred_class.detach().numpy().reshape(1, -1))\n",
        "actual_name = le.inverse_transform(test_label.cpu().detach().numpy().reshape(1, -1))\n",
        "plt.title(f\"Predicted: {pred_name} Actual: {actual_name}\")"
      ],
      "metadata": {
        "id": "CPnPGQFP-yqp"
      },
      "id": "CPnPGQFP-yqp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "t8eY7qlXclCB",
      "metadata": {
        "id": "t8eY7qlXclCB"
      },
      "source": [
        "# Creating the WGAN For Fruits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a9a153-893b-458b-995a-7b209ae18917",
      "metadata": {
        "id": "33a9a153-893b-458b-995a-7b209ae18917"
      },
      "outputs": [],
      "source": [
        "# Steps:\n",
        "# build Generator network\n",
        "# build Discriminator network\n",
        "# build Gradient Penalty Function\n",
        "# build training function:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from torchvision.utils import make_grid"
      ],
      "metadata": {
        "id": "GcSXpItJBWK3"
      },
      "id": "GcSXpItJBWK3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show(tensor, num=25, wandbactive=0, name=''):\n",
        "  data = tensor.detach().cpu()\n",
        "  grid = make_grid(data[:num], nrow=5).permute(1,2,0)\n",
        "  grid = grid/2 + 0.5\n",
        "  plt.imshow(grid.clip(0,1))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "c7wkaIrTBULy"
      },
      "id": "c7wkaIrTBULy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e722ee7-ec97-49de-9768-46d754552f7e",
      "metadata": {
        "id": "1e722ee7-ec97-49de-9768-46d754552f7e"
      },
      "outputs": [],
      "source": [
        "learning_rate_crit = 0.0002\n",
        "learning_rate_gen = 0.0001\n",
        "samples = 10000\n",
        "img_size = (64,64)\n",
        "gan_reshaped = (64,64)\n",
        "bs = 128\n",
        "critic_cycles = 5\n",
        "n_epochs = 70\n",
        "z_dim = 225"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e7e92d3-83cb-4741-95f8-7edb65534e15",
      "metadata": {
        "id": "3e7e92d3-83cb-4741-95f8-7edb65534e15"
      },
      "outputs": [],
      "source": [
        "# Get Overall Set of fruits;\n",
        "# change this to add more samples (preferable 10000)\n",
        "\n",
        "fruits = getRandomFruitDirs(130)\n",
        "fruits = fruits[fruits != '.ipynb_checkpoints']\n",
        "dataset = getSamplesMat(samples, fruits, resize = gan_reshaped)\n",
        "main = dataset[0]\n",
        "labels = dataset[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()"
      ],
      "metadata": {
        "id": "Dp8Gqrq9x8iQ"
      },
      "id": "Dp8Gqrq9x8iQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f046f1-32d6-48a3-9c2a-2d13f568bb01",
      "metadata": {
        "id": "e2f046f1-32d6-48a3-9c2a-2d13f568bb01"
      },
      "outputs": [],
      "source": [
        "main = main.reshape(-1, 64, 64, 3).astype(np.float32)\n",
        "main_norm = main * 2 - 1\n",
        "main_trans = np.transpose(main_norm, (0, 3,1,2)).astype(np.float32, copy=False)\n",
        "print(main.shape)\n",
        "real_data = torch.from_numpy(main_trans)\n",
        "labels = torch.tensor(le.fit_transform(labels)).long()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(main[2].reshape(64,64,3))"
      ],
      "metadata": {
        "id": "Do_yRgjeRZ0f"
      },
      "id": "Do_yRgjeRZ0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "088ade12-0adb-4268-a653-0b88c6e5f34f",
      "metadata": {
        "id": "088ade12-0adb-4268-a653-0b88c6e5f34f"
      },
      "outputs": [],
      "source": [
        "tensor_dataset = TensorDataset(real_data, labels)\n",
        "dataloader = DataLoader(tensor_dataset, batch_size = bs, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_PhC9zsFdt7n",
      "metadata": {
        "id": "_PhC9zsFdt7n"
      },
      "outputs": [],
      "source": [
        "def GenNoise(num, z_dim):\n",
        "    latent = torch.randn(num, z_dim).view(num, z_dim, 1, 1)\n",
        "    return latent.to(device)\n",
        "\n",
        "\n",
        "class GeneratorModel(nn.Module):\n",
        "  def __init__(self, n_dim=16, z_dim = 100):\n",
        "      super().__init__()\n",
        "      self.z_dim = z_dim\n",
        "      self.gen = nn.Sequential(\n",
        "        nn.ConvTranspose2d(z_dim, n_dim*8, 4, 1, 0), # 4x4\n",
        "        nn.BatchNorm2d(n_dim * 8),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ConvTranspose2d(n_dim*8, n_dim*4, 4, 2, 1), # 8x8\n",
        "        nn.BatchNorm2d(n_dim * 4),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ConvTranspose2d(n_dim*4, n_dim*2, 4, 2, 1), # 16x16\n",
        "        nn.BatchNorm2d(n_dim * 2),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ConvTranspose2d(n_dim*2, n_dim*1, 4, 2, 1), # 32 x 32\n",
        "        nn.BatchNorm2d(n_dim * 1),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ConvTranspose2d(n_dim, 3, 4, 2, 1), #64 x 64\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, noise):\n",
        "    x = noise.view(len(noise), self.z_dim, 1, 1)  # 128 x 200 x 1 x 1\n",
        "    return self.gen(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab68986d-67ab-4e7c-b450-7ef5a80af1fd",
      "metadata": {
        "id": "ab68986d-67ab-4e7c-b450-7ef5a80af1fd"
      },
      "outputs": [],
      "source": [
        "class CriticModel(nn.Module):\n",
        "    def __init__(self, n_dim=16):\n",
        "        super().__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            nn.Conv2d(3, n_dim, 4, 2, 1),  # 64x64 -> 32x32\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(n_dim, n_dim*2, 4, 2, 1),  # 32x32 -> 16x16\n",
        "            nn.BatchNorm2d(n_dim*2),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(n_dim*2, n_dim*4, 4, 2, 1),  # 16x16 -> 8x8\n",
        "            nn.BatchNorm2d(n_dim*4),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(n_dim*4, n_dim*8, 4, 2, 1),  # 8x8 -> 4x4\n",
        "            nn.BatchNorm2d(n_dim*8),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(n_dim*8, 1, 4, 1, 0)  # 4x4 -> 1x1\n",
        "        )\n",
        "\n",
        "    def forward(self, image):\n",
        "        return self.disc(image).view(len(image), -1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78518c87-0b04-4a8f-8c4a-2bc9f1e740c0",
      "metadata": {
        "id": "78518c87-0b04-4a8f-8c4a-2bc9f1e740c0"
      },
      "source": [
        "# Test the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "479e3c5f-a2d0-4d77-867a-9d79aadd5910",
      "metadata": {
        "id": "479e3c5f-a2d0-4d77-867a-9d79aadd5910"
      },
      "outputs": [],
      "source": [
        "gen_model = GeneratorModel(z_dim = z_dim)\n",
        "gen_model = gen_model.to(torch.device(device))\n",
        "crit_model = CriticModel()\n",
        "crit_model = crit_model.to(torch.device(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c322f0b7-6fab-4414-88cd-a1b4a7be6d49",
      "metadata": {
        "id": "c322f0b7-6fab-4414-88cd-a1b4a7be6d49"
      },
      "source": [
        "# Defining the Gradient Penalty function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa097f68-396f-48d7-8f73-fe4612dc5322",
      "metadata": {
        "id": "fa097f68-396f-48d7-8f73-fe4612dc5322"
      },
      "outputs": [],
      "source": [
        "# Constructing the gradient penalty function\n",
        "# The gradient penality is used as a regularizer term in the wasserstien loss\n",
        "def get_gp(real, fake, crit, device, gamma = 10):\n",
        "    cur_bs , _, _, _ = real.shape\n",
        "    alpha = torch.rand(cur_bs, 1, 1, 1).to(device)\n",
        "    inter_img = alpha * real + (1-alpha) * fake\n",
        "    inter_img.requires_grad_(True)\n",
        "    predictions = crit(inter_img)\n",
        "    model_gradient = torch.autograd.grad(\n",
        "        inputs = inter_img,\n",
        "        outputs = predictions,\n",
        "        grad_outputs = torch.ones_like(predictions),\n",
        "        retain_graph = True,\n",
        "        create_graph = True,\n",
        "    )[0]\n",
        "\n",
        "    model_gradient = model_gradient.view(len(model_gradient), -1)\n",
        "    gradient_norm = model_gradient.norm(2, dim=1)\n",
        "    gp = ((gradient_norm - 1)**2).mean()\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ad577d2-9dd5-42bc-8b64-7c154bc6a596",
      "metadata": {
        "id": "4ad577d2-9dd5-42bc-8b64-7c154bc6a596"
      },
      "outputs": [],
      "source": [
        "# Construct the optimizer functions:\n",
        "gen_optimizer = torch.optim.Adam(gen_model.parameters(),lr=learning_rate_gen, betas = (0.5, 0.99))\n",
        "crit_optimizer = torch.optim.Adam(crit_model.parameters(),lr=learning_rate_crit, betas = (0.5, 0.99))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4a73869-4ee0-4dc4-9523-797f41e85742",
      "metadata": {
        "id": "b4a73869-4ee0-4dc4-9523-797f41e85742"
      },
      "outputs": [],
      "source": [
        "# Train Function:\n",
        "# Train for 1 epoch only! (DEBUG):\n",
        "n_epochs = 150\n",
        "gen_loss_hist = []\n",
        "cur_step = 0\n",
        "gamma = 10\n",
        "crit_loss_hist = []\n",
        "for epochi in range(n_epochs):\n",
        "    gen_loss_batch = []\n",
        "    crit_loss_batch = []\n",
        "    for real, _ in dataloader:\n",
        "        real = real.to(device)\n",
        "        cur_bs = len(real)\n",
        "        # Training the critic Model\n",
        "        for i in range(critic_cycles):\n",
        "            # Zero Grad\n",
        "\n",
        "            # Generate Fake Noise\n",
        "            fake_noise = GenNoise(cur_bs, z_dim)\n",
        "            fake = gen_model(fake_noise)\n",
        "            # create the real predictions\n",
        "            fake_preds = crit_model(fake.detach()).mean()\n",
        "            real_preds = crit_model(real).mean()\n",
        "            # calculating the gradient penalty:\n",
        "            gp = get_gp(real, fake, crit_model, device)\n",
        "\n",
        "\n",
        "            # Wasserstein Loss\n",
        "            real_loss = fake_preds - real_preds + gamma * gp\n",
        "            crit_loss_batch.append(real_loss.item())\n",
        "\n",
        "            crit_optimizer.zero_grad()\n",
        "            real_loss.backward(retain_graph = True)\n",
        "            crit_optimizer.step()\n",
        "        # Training the generative model:\n",
        "\n",
        "        noise = GenNoise(cur_bs, z_dim)\n",
        "        fake = gen_model(noise)\n",
        "        gen_loss = -crit_model(fake).mean()\n",
        "\n",
        "        gen_optimizer.zero_grad()\n",
        "        gen_loss.backward()\n",
        "        gen_optimizer.step()\n",
        "\n",
        "        gen_loss_batch.append(gen_loss.item())\n",
        "        cur_step += 1\n",
        "        if cur_step%100 == 0:\n",
        "          gan_noise = GenNoise(cur_bs, z_dim)\n",
        "          sample_image = gen_model(gan_noise)\n",
        "          show(real)\n",
        "          show(sample_image)\n",
        "\n",
        "\n",
        "\n",
        "    gen_loss_hist.append(np.mean(gen_loss_batch))\n",
        "    crit_loss_hist.append(np.mean(crit_loss_batch))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(gen_loss_hist, label=\"Generator Loss\")\n",
        "plt.plot(crit_loss_hist, label = \"Critic Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"GAN Generator and Critic Loss (Wasserstien Loss)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n"
      ],
      "metadata": {
        "id": "5aWTnNtwfG0-"
      },
      "id": "5aWTnNtwfG0-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator Test:\n",
        "gan_noise = GenNoise(10, z_dim)\n",
        "sample_image = gen_model(gan_noise)\n",
        "print(sample_image.shape)\n",
        "targ_img = sample_image.cpu().permute(0, 2, 3, 1).detach().numpy()\n",
        "targ_img = targ_img/2 + 0.5\n",
        "plt.imshow(targ_img[1])"
      ],
      "metadata": {
        "id": "iHArVuIJfLtc"
      },
      "id": "iHArVuIJfLtc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_model = GeneratorModel(z_dim=250)\n",
        "crit_model = CriticModel()\n",
        "\n",
        "gen_model = gen_model.to(device)\n",
        "crit_model = crit_model.to(device)\n",
        "train(gen_model, crit_model, dataloader, 250, 10)"
      ],
      "metadata": {
        "id": "IIwA2eKxSEOv"
      },
      "id": "IIwA2eKxSEOv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LLDzH5g5uYcE"
      },
      "id": "LLDzH5g5uYcE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}